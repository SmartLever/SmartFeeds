{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Play ground for Engeenering the Prompt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import query_data\n",
    "import datetime as dt\n",
    "import pytz\n",
    "from langchain.llms import OpenAIChat\n",
    "import configparser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "openai.api_key = config['openai']['api_key']\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['openai']['api_key']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "llm = OpenAIChat(temperature=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "prompt_narrative_crypto = \"\"\"Create a list of crypto $TOKEN from the text and follow this guide:\n",
    "                             1) Tokens mentioned in the tweets should be in the format $TOKEN, but not necessarily.\n",
    "                             2) Unify information for each $TOKEN.\n",
    "                             3) For each $TOKEN, inclued narrative  or relevant information.\n",
    "                             4) Add catalysts for each token if possible.\n",
    "                             5) if No specific $TOKEN mentioned, join all the text together.\n",
    "    response list example: \"1) $BTC:  Posible pump due to Elon Musk's tweet. Catalyst: Next convention in march.\n",
    "                       2) $HPK:  Strong narrative  Catalyst: No info.\n",
    "                       3) General Narrative:\n",
    "                          - Many altcoins are currently experiencing a significant drop in price.\n",
    "                          - CPI data is expected to be released today.\n",
    "                       \"\n",
    "\n",
    "   {text}\n",
    "   \"\"\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "prompt_narrative_crypto = \"\"\"Given the following text:\"{text}\"\n",
    "\n",
    "Create a list of crypto tokens with the corresponding narratives\n",
    "and potential catalysts for each token. Use the following guidelines:\n",
    "\n",
    "Use the format $TOKEN or TOKEN is used when mentioning a specific token in the tweets.\n",
    "If no specific $TOKEN is mentioned, summarize the general narrative.\n",
    "Unify information for each $TOKEN.\n",
    "Include relevant information for each $TOKEN, such as market trends, news, or events.\n",
    "Add potential catalysts for each token if possible.\n",
    "\n",
    "After creating the list, structure your response as follows:\n",
    "\n",
    "\"1) $TOKEN1: [narrative]. Catalysts: [potential catalysts].\n",
    "2) $TOKEN2: [narrative]. Catalysts: [potential catalysts].\n",
    ".....\n",
    "n) $TOKENn: [narrative]. Catalysts: [potential catalysts].\n",
    "General Narrative: [general summary of market trends].\"\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# load tweets\n",
    "tweets = pd.read_pickle(\"tweets_crypto.pkl\")\n",
    "# get tweets from last 24 hours\n",
    "last_24 = dt.datetime.now(pytz.UTC) - dt.timedelta(hours=24)\n",
    "tweets = [ tweet for tweet in tweets  if tweet.created_at >= last_24]\n",
    "docs = query_data.create_thread_docs(tweets, filer_len=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\n1) $STG: Bought a little. Will add on further strength in the v low 0.80â€™s. Catalysts: potential breakout on a break of 0.17, targets at 0.22, 0.25, and 0.30.\\n2) $LAMB: AI-focused token with 50% growth and 1-day pump duration. Catalysts: AI narrative.\\n3) $CULT: zkEVM-focused token with 30% growth and 1-day pump duration. Catalysts: zkEVM narrative.\\n4) $AIPAD: Arbitrum-focused token with 20% growth and 2-hour pump duration. Catalysts: Arbitrum narrative.\\nGeneral Narrative: Many alts are currently 30-40% off from highs just 2 weeks ago. Binance is dropping the ball on offering spot twap. Staked ETH participants are at a loss with the average staking price at $2.1k.'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PROMPT = PromptTemplate(template=prompt_narrative_crypto, input_variables=[\"text\"])\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=PROMPT)\n",
    "chain.run(docs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combine summary win tokens more than 4000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "refine_template = (\n",
    "        \"your job is to create a list of crypto $TOKEN from the text and follow this guide:\\n\"\n",
    "                             \"1) Tokens mentioned in the tweets should be in the format $TOKEN\\n\"\n",
    "                             \"2) Unify information for each $TOKEN.\\n\"\n",
    "                             \"3) For each $TOKEN, inclued narrative  or relevant information.\\n\"\n",
    "                             \"4) Add catalysts for each token if possible.\\n\"\n",
    "                             \"5) if No specific $TOKEN mentioned, include a general narrative.\\n\"\n",
    "        \"We have provided an existing respond up to a certain point: {existing_answer}\\n\"\n",
    "        \"We have the opportunity to refine the existing list of $TOKEN \\n\"\n",
    "        \"(only if needed) with some more text below.\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"{text}\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"Given the new text, refine the original list\"\n",
    "        \"If the text isn't useful, return the original list.\"\n",
    "    )\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"text\"],\n",
    "    template=refine_template,\n",
    ")\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\", return_intermediate_steps=True,\n",
    "                             question_prompt=PROMPT, refine_prompt=refine_prompt)\n",
    "chain({\"input_documents\": docs}, return_only_outputs=True)['output_text']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
