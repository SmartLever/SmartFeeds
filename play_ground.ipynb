{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Play ground for Engeenering the Prompt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import query_data\n",
    "import datetime as dt\n",
    "import pytz\n",
    "from langchain.llms import OpenAIChat\n",
    "import configparser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "openai.api_key = config['openai']['api_key']\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['openai']['api_key']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "llm = OpenAIChat(temperature=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "\n",
    "prompt_narrative_crypto = \"\"\"Create a list of crypto $TOKEN from the text and follow this guide:\n",
    "                             1) Tokens mentioned in the tweets should be in the format $TOKEN, but not necessarily.\n",
    "                             2) Unify information for each $TOKEN.\n",
    "                             3) For each $TOKEN, inclued narrative  or relevant information.\n",
    "                             4) Add catalysts for each token if possible.\n",
    "                             5) if No specific $TOKEN mentioned, join all the text together.\n",
    "    response list example: \"1) $BTC:  Posible pump due to Elon Musk's tweet. Catalyst: Next convention in march.\n",
    "                       2) $HPK:  Strong narrative  Catalyst: No info.\n",
    "                       3) General Narrative:\n",
    "                          - Many altcoins are currently experiencing a significant drop in price.\n",
    "                          - CPI data is expected to be released today.\n",
    "                       \"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   {text}\n",
    "   \"\"\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# load tweets\n",
    "tweets = pd.read_pickle(\"tweets_crypto.pkl\")\n",
    "# get tweets from last 24 hours\n",
    "last_12 = dt.datetime.now(pytz.UTC) - dt.timedelta(hours=24)\n",
    "tweets = [ tweet for tweet in tweets  if tweet.created_at >= last_12]\n",
    "docs = query_data.create_thread_docs(tweets, filer_len=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n\\n1) $SSV: A fundamentally good coin and a firm favorite to trade. No specific catalyst mentioned.\\n2) $RIF: Targets on a break of 0.17 with potential spots to book something at 0.22, 0.25, and 0.30. Looking for re-entry. Catalyst: No specific catalyst mentioned.\\n3) $STG: Bought a little and on the watchlist. Will add on further strength in the very low 0.80's. Catalyst: No specific catalyst mentioned.\\n4) General Narrative:\\n- Pitfalls of growing from 2k =&gt; 13k followers: Can't mention early low caps [500k - $2-3M] anymore as it would be seen as unethical shilling and P&amp;D.\\n- Many altcoins are currently experiencing a significant drop in price, with some 30-40% off from highs just 2 weeks ago.\\n- There is currently 17.4M staked ETH, with the average staking price at $2.1k, leaving most participants at a loss now.\\n- Looking for a non z-tier exchange offering spot twap, not interested in API solutions.\\n- Autocorrect mistake in phrasing 2023 high.\""
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_narrative_crypto, input_variables=[\"text\"])\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=PROMPT)\n",
    "chain.run(docs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combine summary win tokens more than 4000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ujTxfa4kohWwQMLMLnUCZg8A on requests per min. Limit: 20 / min. Current: 30 / min. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-ujTxfa4kohWwQMLMLnUCZg8A on requests per min. Limit: 20 / min. Current: 40 / min. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "refine_template = (\n",
    "        \"your job is to create a list of crypto $TOKEN from the text and follow this guide:\\n\"\n",
    "                             \"1) Tokens mentioned in the tweets should be in the format $TOKEN\\n\"\n",
    "                             \"2) Unify information for each $TOKEN.\\n\"\n",
    "                             \"3) For each $TOKEN, inclued narrative  or relevant information.\\n\"\n",
    "                             \"4) Add catalysts for each token if possible.\\n\"\n",
    "                             \"5) if No specific $TOKEN mentioned, include a general narrative.\\n\"\n",
    "        \"We have provided an existing respond up to a certain point: {existing_answer}\\n\"\n",
    "        \"We have the opportunity to refine the existing list of $TOKEN \\n\"\n",
    "        \"(only if needed) with some more text below.\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"{text}\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"Given the new text, refine the original list\"\n",
    "        \"If the text isn't useful, return the original list.\"\n",
    "    )\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"text\"],\n",
    "    template=refine_template,\n",
    ")\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\", return_intermediate_steps=True,\n",
    "                             question_prompt=PROMPT, refine_prompt=refine_prompt)\n",
    "chain({\"input_documents\": docs}, return_only_outputs=True)['output_text']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
